{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to use cuda, you can specify the ID of the device\n",
    "# import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '5'\n",
    "# and set the use_cuda parameter to True\n",
    "use_cuda = True # otherwise, set it to False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ru_detoxification_evaluation import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading input dataset and results of model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We suppose that the input dataset is a dataframe with original toxic sentences \n",
    "# and/or with neutral refenrences\n",
    "df = pd.read_csv('../data/input/dev.tsv', sep='\\t')\n",
    "df = df.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                                       toxic_comment  \\\n0  пиздеж! температуры горения хватит чтобы её ра...   \n1           а ты чмо там был.ты вообще служил.гандон   \n\n                                    neutral_comment1  \\\n0  Враньё! Температуры горения хватит чтобы ее ра...   \n1                    А ты там был? Ты вообще служил?   \n\n                                    neutral_comment2  \\\n0  неправда,температуры горения хватит чтобы расп...   \n1                                                      \n\n                                    neutral_comment3  \n0  Враньё! Температуры горения хватит на чтобы её...  \n1                                                     ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>toxic_comment</th>\n      <th>neutral_comment1</th>\n      <th>neutral_comment2</th>\n      <th>neutral_comment3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>пиздеж! температуры горения хватит чтобы её ра...</td>\n      <td>Враньё! Температуры горения хватит чтобы ее ра...</td>\n      <td>неправда,температуры горения хватит чтобы расп...</td>\n      <td>Враньё! Температуры горения хватит на чтобы её...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>а ты чмо там был.ты вообще служил.гандон</td>\n      <td>А ты там был? Ты вообще служил?</td>\n      <td></td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_inputs = df['toxic_comment'].tolist()\n",
    "\n",
    "neutral_references = []\n",
    "for index, row in df.iterrows():\n",
    "    neutral_references.append([row['neutral_comment1'], row['neutral_comment2'], row['neutral_comment3']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We suppose that the model outputs are saved as .txt file seperated with '\\n'\n",
    "with open('../data/output/new-caif-rugpt3-paraphraser_dev.txt', 'r', encoding='utf-8') as file:\n",
    "    preds = file.readlines()\n",
    "preds = [sentence.strip() for sentence in preds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Style Transfer Accuracy (STA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ru_detoxification_metrics import evaluate_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_model, style_tokenizer = load_model('s-nlp/russian_toxicity_classifier', use_cuda=use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/25 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c1c355ba685349f99874dc36c661e625"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy = evaluate_style(\n",
    "    model = style_model,\n",
    "    tokenizer = style_tokenizer,\n",
    "    texts = preds,\n",
    "    target_label=0,  # 1 is toxic, 0 is neutral\n",
    "    batch_size=32, \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Style transfer accuracy (STA):  0.7680249810218811\n"
     ]
    }
   ],
   "source": [
    "print(f'Style transfer accuracy (STA):  {np.mean(accuracy)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meaning Preservation Score (SIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ru_detoxification_metrics import evaluate_cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cointegrated/LaBSE-en-ru were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "meaning_model, meaning_tokenizer = load_model('cointegrated/LaBSE-en-ru', use_cuda=use_cuda, model_class=AutoModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/25 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "53da9804bf8b484194ba119a62164571"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/25 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "274bcc7c703248329ebc6d548c8635b9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "similarity = evaluate_cosine_similarity(\n",
    "    model = meaning_model,\n",
    "    tokenizer = meaning_tokenizer,\n",
    "    original_texts = toxic_inputs,\n",
    "    rewritten_texts = preds,\n",
    "    batch_size=32,\n",
    "    verbose=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meaning preservation (SIM):  0.39833030104637146\n"
     ]
    }
   ],
   "source": [
    "print(f'Meaning preservation (SIM):  {np.mean(similarity)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fluency score (FL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ru_detoxification_metrics import evaluate_cola_relative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cola_model, cola_tolenizer = load_model('s-nlp/rubert-base-corruption-detector', use_cuda=use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/25 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "54dde22671274f5a91715b7bac80768c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/25 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b28535c287bb4657b92e2799ab87d010"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fluency = evaluate_cola_relative(\n",
    "    model = cola_model,\n",
    "    tokenizer = cola_tolenizer,\n",
    "    original_texts = toxic_inputs,\n",
    "    rewritten_texts = preds,\n",
    "    target_label=1,\n",
    "    batch_size=32,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fluency score (FL):  0.8065676093101501\n"
     ]
    }
   ],
   "source": [
    "print(f'Fluency score (FL):  {np.mean(fluency)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint score (J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint = accuracy * similarity * fluency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "array([2.46479645e-01, 5.07902682e-01, 1.96248759e-02, 6.55506074e-01,\n       0.00000000e+00, 7.30593741e-01, 1.14290245e-01, 5.86284436e-02,\n       8.55390504e-02, 1.08936131e-01, 5.35859346e-01, 5.46079397e-01,\n       7.51483366e-02, 2.32018933e-01, 7.06034184e-01, 7.26914257e-02,\n       2.04498872e-01, 3.83508801e-01, 3.28810960e-02, 1.10529391e-02,\n       0.00000000e+00, 4.39830035e-01, 5.70685685e-01, 1.22965522e-01,\n       3.50806005e-02, 6.48836553e-01, 1.31133467e-01, 1.10794321e-01,\n       2.69820206e-02, 1.05388025e-02, 5.00120744e-02, 3.13538671e-01,\n       2.24190444e-01, 2.78390050e-01, 3.65133733e-01, 1.25230089e-01,\n       1.75598308e-01, 3.79498512e-01, 9.26436037e-02, 1.23347923e-01,\n       7.41392493e-01, 6.35362029e-01, 2.58834869e-01, 3.71663332e-01,\n       3.11604619e-01, 3.92805427e-01, 5.60602434e-02, 3.65320176e-01,\n       2.39653349e-01, 5.99738836e-01, 4.04670760e-02, 1.56458125e-01,\n       2.47989163e-01, 4.10046101e-01, 1.25206942e-02, 1.11533046e-01,\n       7.06032589e-02, 1.80818528e-01, 3.68955672e-01, 8.12664866e-01,\n       5.37239790e-01, 2.04849765e-01, 3.50978877e-03, 2.52459168e-01,\n       5.11928439e-01, 0.00000000e+00, 1.52553394e-01, 4.58106622e-02,\n       8.10956433e-02, 4.38242674e-01, 4.01173741e-01, 3.74774665e-01,\n       2.39234105e-01, 2.98180338e-02, 1.16236307e-01, 7.16176778e-02,\n       9.82759297e-02, 7.62168586e-01, 1.00553878e-01, 2.03579754e-01,\n       6.15479685e-02, 4.50146534e-02, 9.89173204e-02, 8.57527018e-01,\n       2.97883034e-01, 1.91032735e-03, 1.89110078e-02, 5.87860718e-02,\n       0.00000000e+00, 2.39454299e-01, 1.52322603e-03, 9.17614400e-02,\n       3.13977823e-02, 2.08681718e-01, 9.04905260e-01, 1.84807360e-01,\n       3.17438453e-01, 9.62837413e-02, 2.57764876e-01, 3.91866326e-01,\n       0.00000000e+00, 2.87378971e-02, 2.79652685e-01, 3.81389499e-01,\n       2.14236379e-01, 4.04137820e-01, 2.04524085e-01, 6.18063033e-01,\n       1.06153369e-01, 7.12055191e-02, 1.88706309e-01, 4.17850196e-01,\n       0.00000000e+00, 5.52694559e-01, 0.00000000e+00, 1.76748082e-01,\n       8.19865912e-02, 3.41493398e-01, 5.38226783e-01, 1.12457864e-01,\n       5.20741800e-03, 4.41238075e-01, 1.17389463e-01, 2.83520836e-02,\n       1.88624814e-01, 0.00000000e+00, 7.92949796e-02, 2.53931731e-01,\n       7.43256062e-02, 0.00000000e+00, 5.02122641e-01, 0.00000000e+00,\n       3.65536474e-02, 4.70685139e-02, 3.93630285e-03, 7.45081156e-02,\n       2.92663462e-02, 4.22124267e-01, 8.60955536e-01, 0.00000000e+00,\n       3.27305496e-01, 6.89388692e-01, 3.24294001e-01, 0.00000000e+00,\n       2.86106408e-01, 3.85196149e-01, 5.45046687e-01, 3.12297735e-02,\n       0.00000000e+00, 3.54558289e-01, 4.83164907e-01, 5.32662809e-01,\n       1.70309618e-01, 1.75436810e-01, 0.00000000e+00, 2.25699022e-01,\n       0.00000000e+00, 1.31349221e-01, 0.00000000e+00, 2.97854871e-01,\n       5.39343245e-02, 0.00000000e+00, 0.00000000e+00, 7.15333045e-01,\n       0.00000000e+00, 2.65982062e-01, 2.11385712e-01, 0.00000000e+00,\n       7.84803212e-01, 2.40115836e-01, 0.00000000e+00, 2.37668663e-01,\n       5.52647710e-01, 5.52213430e-01, 1.89354166e-01, 2.12791011e-01,\n       2.62255937e-01, 5.17595828e-01, 2.09866703e-01, 3.26876730e-01,\n       3.27144302e-02, 0.00000000e+00, 7.95439407e-02, 3.41369808e-01,\n       2.80010581e-01, 8.04376900e-02, 5.49307978e-03, 1.04079321e-01,\n       4.03580070e-01, 8.61361176e-02, 0.00000000e+00, 5.65950833e-02,\n       0.00000000e+00, 4.02206987e-01, 4.44099307e-01, 3.69506419e-01,\n       4.35654789e-01, 0.00000000e+00, 3.24184716e-01, 4.53567803e-01,\n       2.01219857e-01, 4.42758560e-01, 0.00000000e+00, 3.43594581e-01,\n       0.00000000e+00, 3.41116637e-01, 1.57820791e-01, 5.20543717e-02,\n       1.34036411e-02, 8.36951792e-01, 4.41606700e-01, 2.43515611e-01,\n       4.45145905e-01, 9.65479091e-02, 7.29093313e-01, 1.50120869e-01,\n       6.45323277e-01, 1.27430484e-01, 3.40706520e-02, 4.73975480e-01,\n       4.09389846e-02, 7.60981988e-04, 0.00000000e+00, 2.35928327e-01,\n       1.49172023e-01, 5.90973757e-02, 4.78664577e-01, 3.68271321e-01,\n       2.33856728e-03, 4.62246537e-02, 3.66985828e-01, 6.15247309e-01,\n       1.75775960e-01, 1.55360937e-01, 2.92737246e-01, 4.49899323e-02,\n       4.42065671e-02, 5.05237818e-01, 7.84451216e-02, 2.75658872e-02,\n       4.69391286e-01, 0.00000000e+00, 0.00000000e+00, 1.03877902e-01,\n       1.73418894e-01, 5.98919570e-01, 0.00000000e+00, 5.11863232e-01,\n       6.54308945e-02, 6.27802908e-02, 6.22954130e-01, 2.42610365e-01,\n       0.00000000e+00, 2.34596968e-01, 1.93886813e-02, 5.98764479e-01,\n       2.56288141e-01, 3.16179395e-01, 2.99467947e-02, 2.89867997e-01,\n       0.00000000e+00, 4.39610273e-01, 2.19705716e-01, 0.00000000e+00,\n       1.29423440e-01, 0.00000000e+00, 4.11432236e-01, 7.02512503e-01,\n       5.93629293e-02, 1.71430767e-01, 2.01595142e-01, 2.99076915e-01,\n       5.74196696e-01, 2.52829522e-01, 1.14448264e-01, 0.00000000e+00,\n       0.00000000e+00, 5.56697965e-01, 3.30144959e-03, 7.15943933e-01,\n       0.00000000e+00, 0.00000000e+00, 3.29643041e-01, 9.34318081e-02,\n       4.82212901e-01, 1.81355670e-01, 5.36505044e-01, 5.64197078e-02,\n       1.04130186e-01, 6.97383210e-02, 1.56632364e-01, 3.33502203e-01,\n       1.40304551e-01, 4.86747399e-02, 1.69417396e-01, 5.84997423e-02,\n       0.00000000e+00, 4.79182363e-01, 3.31593812e-01, 3.71117502e-01,\n       1.39440894e-01, 3.78015339e-01, 8.26861411e-02, 1.44677475e-01,\n       1.40788242e-01, 4.89184380e-01, 0.00000000e+00, 1.06245473e-01,\n       3.38211581e-02, 4.98798668e-01, 9.53671522e-03, 4.71509516e-01,\n       3.56138080e-01, 4.38146703e-02, 4.80648845e-01, 4.22214359e-01,\n       4.51911181e-01, 4.00036126e-01, 0.00000000e+00, 2.86839068e-01,\n       5.25081098e-01, 1.45406827e-01, 2.42366299e-01, 2.13340193e-01,\n       1.57916754e-01, 3.63875926e-02, 1.76982999e-01, 4.93598312e-01,\n       1.34731218e-01, 3.08193624e-01, 3.09688091e-01, 1.28979743e-01,\n       7.09557116e-01, 5.99332631e-01, 8.04217160e-02, 1.54739276e-01,\n       9.71892029e-02, 9.71954763e-02, 3.75534385e-01, 5.96910752e-02,\n       4.21808124e-01, 5.22559643e-01, 1.69616099e-02, 8.48849490e-02,\n       0.00000000e+00, 2.78590508e-02, 5.27315736e-01, 1.71307966e-01,\n       8.99400786e-02, 3.78591210e-01, 2.51913488e-01, 2.83747017e-01,\n       5.28330147e-01, 8.02246556e-02, 7.79838115e-02, 0.00000000e+00,\n       1.61256358e-01, 7.33579636e-01, 0.00000000e+00, 1.25614971e-01,\n       3.46831024e-01, 5.76706827e-02, 2.04252154e-01, 7.85997570e-01,\n       4.80027974e-01, 2.83905953e-01, 1.61975846e-01, 2.53594041e-01,\n       2.42320374e-01, 4.20982629e-01, 6.92193329e-01, 1.91124231e-01,\n       1.85971811e-01, 6.74206376e-01, 7.95754492e-02, 3.34017962e-01,\n       5.85950077e-01, 5.99813104e-01, 2.20708162e-01, 8.76889303e-02,\n       0.00000000e+00, 2.87323873e-02, 3.41372043e-01, 0.00000000e+00,\n       6.37205690e-02, 4.75113183e-01, 2.41618335e-01, 1.05329894e-01,\n       1.97827205e-01, 1.75573274e-01, 2.62057707e-02, 0.00000000e+00,\n       5.55175722e-01, 2.83029377e-02, 5.08104324e-01, 1.38257846e-01,\n       0.00000000e+00, 2.61566460e-01, 5.87490797e-01, 4.12643820e-01,\n       4.35410738e-02, 1.13855064e-01, 3.97049457e-01, 2.26104446e-02,\n       3.33499193e-01, 1.39892265e-01, 2.78898031e-01, 3.27353448e-01,\n       3.07283271e-02, 4.20393758e-02, 2.01679412e-02, 5.76872639e-02,\n       1.92315042e-01, 5.67990914e-02, 4.62096304e-01, 3.08204114e-01,\n       9.43435073e-01, 1.10598281e-01, 3.50654215e-01, 8.23344663e-02,\n       4.77145910e-02, 1.83586165e-01, 1.32963955e-01, 3.14084291e-01,\n       1.71641827e-01, 2.70208418e-01, 1.03353128e-01, 4.37656999e-01,\n       0.00000000e+00, 5.19147575e-01, 1.09281756e-01, 6.08796068e-02,\n       7.08279684e-02, 5.53315282e-01, 6.25046417e-02, 2.10464373e-01,\n       4.47645821e-02, 4.05397899e-02, 6.78998083e-02, 0.00000000e+00,\n       6.78349555e-01, 5.63921109e-02, 6.92652091e-02, 1.10447733e-02,\n       3.52344930e-01, 4.02583070e-02, 2.20411420e-02, 3.18618804e-01,\n       4.59133863e-01, 9.22555476e-02, 5.59491634e-01, 7.44729862e-02,\n       2.76831031e-01, 5.90617120e-01, 4.22584057e-01, 6.12497211e-01,\n       4.13224906e-01, 2.72690237e-01, 5.79523921e-01, 7.18837157e-02,\n       6.01520777e-01, 3.22824307e-02, 2.93675438e-02, 1.69606939e-01,\n       1.48355272e-02, 6.50799036e-01, 4.24766801e-02, 3.34570646e-01,\n       3.14934582e-01, 1.69032499e-01, 4.65465561e-02, 2.61147290e-01,\n       4.39067453e-01, 0.00000000e+00, 1.33203745e-01, 3.60721380e-01,\n       2.13755965e-01, 2.44197980e-01, 3.45495433e-01, 2.13294834e-01,\n       3.66823465e-01, 4.95961279e-01, 2.72073716e-01, 2.46803656e-01,\n       3.13217670e-01, 5.85525095e-01, 7.43205130e-01, 2.13822857e-01,\n       3.03159859e-02, 2.54029036e-02, 3.03223073e-01, 5.60767204e-02,\n       5.58044687e-02, 1.27774552e-01, 1.08592018e-01, 2.71557838e-01,\n       7.02286303e-01, 1.74230654e-02, 2.03982994e-01, 4.32715237e-01,\n       2.91201696e-02, 1.87830314e-01, 2.05606252e-01, 0.00000000e+00,\n       7.31450543e-02, 1.03788778e-01, 1.89705953e-01, 2.02596843e-01,\n       6.41200960e-01, 2.38565616e-02, 1.95024516e-02, 0.00000000e+00,\n       4.33220677e-02, 5.02275586e-01, 3.92968833e-01, 3.76871228e-01,\n       1.54072195e-02, 2.92166948e-01, 4.78065759e-02, 6.18649781e-01,\n       7.53266513e-02, 1.30154848e-01, 9.06596929e-02, 3.14298779e-01,\n       2.94149339e-01, 9.94691908e-01, 0.00000000e+00, 7.12581038e-01,\n       4.14920866e-01, 4.92666930e-01, 2.44184569e-01, 1.61134936e-02,\n       5.85978329e-01, 5.10342002e-01, 9.21051800e-02, 2.77914703e-01,\n       1.49806794e-02, 3.74859720e-01, 0.00000000e+00, 1.18431680e-01,\n       2.08617941e-01, 1.98351201e-02, 3.40263173e-02, 3.61865349e-02,\n       3.60139161e-01, 5.63566387e-01, 5.23425043e-01, 2.42842287e-01,\n       9.50202271e-02, 3.39710027e-01, 1.41156301e-01, 5.77849299e-02,\n       1.52775005e-01, 0.00000000e+00, 3.31382096e-01, 6.81695938e-02,\n       1.97486021e-02, 5.76643527e-01, 2.22638384e-01, 4.52683941e-02,\n       3.86895150e-01, 1.49198055e-01, 1.11473486e-01, 9.69588235e-02,\n       1.54570043e-01, 3.57686371e-01, 7.36266822e-02, 3.53088230e-01,\n       3.86653125e-01, 1.50840387e-01, 4.11589026e-01, 1.30958602e-01,\n       2.36494783e-02, 3.06202490e-02, 3.60345334e-01, 3.07540931e-02,\n       0.00000000e+00, 1.55852884e-01, 1.49097014e-02, 2.01891676e-01,\n       1.83744002e-02, 1.26754493e-01, 2.84239799e-01, 7.16597736e-01,\n       0.00000000e+00, 0.00000000e+00, 3.83916110e-01, 1.72385678e-01,\n       0.00000000e+00, 2.48585254e-01, 1.29404906e-02, 2.62051105e-01,\n       8.88433903e-02, 6.69240594e-01, 1.78864628e-01, 3.03013891e-01,\n       0.00000000e+00, 1.12933395e-02, 1.54562024e-02, 2.84002330e-02,\n       4.52002972e-01, 2.68054921e-02, 1.41596362e-01, 4.18958157e-01,\n       5.55291772e-01, 4.35296327e-01, 7.25034997e-02, 1.22755729e-01,\n       2.41282046e-01, 0.00000000e+00, 7.86146224e-02, 2.83623170e-02,\n       2.38234743e-01, 7.87639678e-01, 9.73232761e-02, 1.07825637e-01,\n       4.09249127e-01, 2.80366302e-03, 7.22864747e-01, 3.09957206e-01,\n       0.00000000e+00, 2.88928270e-01, 3.09494764e-01, 2.24920571e-01,\n       0.00000000e+00, 1.46601677e-01, 5.95694900e-01, 0.00000000e+00,\n       8.54448155e-02, 1.07961446e-01, 4.70163375e-01, 1.96934678e-02,\n       3.29143442e-02, 6.59335032e-02, 6.24367177e-01, 3.73552650e-01,\n       3.97568233e-02, 5.90532925e-03, 1.47620678e-01, 2.44747669e-01,\n       4.76708919e-01, 8.08703899e-02, 7.75142461e-02, 2.15419158e-02,\n       0.00000000e+00, 5.80302417e-01, 0.00000000e+00, 2.03861192e-01,\n       2.82974213e-01, 3.30220386e-02, 6.09474063e-01, 0.00000000e+00,\n       5.37482440e-01, 0.00000000e+00, 0.00000000e+00, 4.29231077e-02,\n       3.30634788e-02, 4.06055540e-01, 7.72799030e-02, 2.59391546e-01,\n       3.32825750e-01, 2.26727352e-01, 6.11758888e-01, 3.35101545e-01,\n       6.65320754e-02, 2.44304780e-02, 0.00000000e+00, 2.90385522e-02,\n       4.34827842e-02, 5.00844598e-01, 1.42017961e-01, 7.87993222e-02,\n       1.47802547e-01, 2.71290898e-01, 2.08667353e-01, 8.39619264e-02,\n       5.72350979e-01, 2.39205975e-02, 4.46271002e-01, 4.85285729e-01,\n       4.22085166e-01, 1.20945126e-01, 7.79639632e-02, 3.43849249e-02,\n       7.16528744e-02, 0.00000000e+00, 1.41688213e-01, 1.21900931e-01,\n       3.52081507e-01, 3.05671424e-01, 5.90697266e-02, 6.63136303e-01,\n       5.03994763e-01, 3.47686291e-01, 2.01370969e-01, 6.09973213e-03,\n       1.29410878e-01, 6.27902389e-01, 7.10723549e-02, 2.85416424e-01,\n       1.50989573e-02, 2.54047364e-01, 1.63196623e-01, 3.08292564e-02,\n       1.20365448e-01, 2.78555490e-02, 2.59955615e-01, 0.00000000e+00,\n       1.67054489e-01, 5.47364056e-01, 1.57394752e-01, 6.87849820e-01,\n       1.08239546e-01, 7.95091167e-02, 3.21365714e-01, 1.91323072e-01,\n       3.44125867e-01, 9.21700001e-02, 7.32918441e-01, 6.52937710e-01,\n       4.31329384e-02, 4.34838533e-01, 6.63422346e-02, 4.11804095e-02,\n       3.49902570e-01, 2.79182076e-01, 2.72911251e-01, 5.41594625e-01,\n       2.26251438e-01, 7.25296512e-02, 1.11546546e-01, 6.06397450e-01,\n       8.34140003e-01, 7.27384761e-02, 8.66599008e-03, 4.04402137e-01,\n       3.89536172e-01, 4.57618445e-01, 3.55327010e-01, 5.20890713e-01,\n       4.49895024e-01, 4.42720801e-02, 2.99489856e-01, 2.85890371e-01,\n       8.07167962e-02, 1.78227246e-01, 2.72741288e-01, 3.34248208e-02,\n       5.56122780e-01, 5.71180940e-01, 1.30080536e-01, 7.38818705e-01,\n       0.00000000e+00, 3.19060087e-01, 4.79743332e-02, 1.42483965e-01,\n       1.24680199e-01, 4.63459581e-01, 3.40325385e-02, 3.14698845e-01,\n       2.45038439e-02, 1.62484095e-01, 1.95722938e-01, 6.22208118e-01,\n       4.31233123e-02, 2.28899457e-02, 2.08945066e-01, 6.52038574e-01,\n       1.54633373e-01, 8.55263025e-02, 3.76087248e-01, 8.41336921e-02,\n       5.53177893e-01, 2.77831435e-01, 5.02700284e-02, 3.69376004e-01,\n       0.00000000e+00, 9.81262252e-02, 5.75012088e-01, 3.97909671e-01,\n       4.82264251e-01, 1.72623247e-01, 6.23568118e-01, 0.00000000e+00,\n       4.43642557e-01, 4.50573832e-01, 2.08636358e-01, 5.95157146e-01,\n       2.58047462e-01, 6.29748464e-01, 0.00000000e+00, 4.24555987e-01,\n       1.77433252e-01, 1.04017429e-01, 4.28062350e-01, 9.85104358e-04,\n       7.34764636e-01, 8.99383426e-01, 2.15214550e-01, 1.55823559e-01],\n      dtype=float32)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint score (J):   0.2373957484960556\n"
     ]
    }
   ],
   "source": [
    "print(f'Joint score (J):   {np.mean(joint)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "0.18001422"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy[accuracy <= 0.5].mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "0.3699633"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity[accuracy > 0.5].mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "0.48400152"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity[accuracy <= 0.5].mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChrF1 with references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.chrf_score import corpus_chrf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.2831523701734911"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_chrf(neutral_references, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
